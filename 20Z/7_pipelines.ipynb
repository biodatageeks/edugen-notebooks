{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bwa index /tmp/jovyan/work/git/edugen_pub/ref/ref.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzenie potoków przetwarzania danych\n",
    "\n",
    "Na dzisiejszych zajęciach jak również na zajęciach z genomiki mieliśmy okazję zapoznać się z programami służącymi do obróbki danych pochodzących z sekwencjonowania wysokoprzepustowego. Jest to proces wieloetapowy, gdzie wykorzystywane są różne narzedzia a operacje wykonywane są na różnych rodzajach plików wejściowych generując nowego rodzaju dane. Biorąc pod uwage mnogość etapów analizy, jak również konieczność analizy wielu plików na raz ręczne wykonywanie po koleji kolejnych etapów analizy staje się niepraktyczne i nieefektywne. W odpowiedzi na te wyzwania stworzono programy do zarządzania przepływem danych, tzw. języki definicji przepływu pracy (ang. Workflow languages).\n",
    "\n",
    "## Najpopularniejsze rodzaje języków definicji przepływu pracy\n",
    "Języki definicji przepływu pracy zapewniają ustrukturyzowane ramy do opisywania i organizowania serii zadań wymaganych do analizy danych. Istnieje wiele języków definiowania przepływów pracy, używanych do pisania potoków obliczeniowych.\n",
    "\n",
    "### Nextflow\n",
    "<div>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e1/Logo_Nextflow_%28new%29.png\"\n",
    "width=400/>\n",
    "</div>\n",
    "\n",
    "[Strona WWW](https://www.nextflow.io/) \\\n",
    "Potok Nextflow składa się z jednego lub więcej modułów lub procesów. Nextflow umożliwia wykonanie skryptu, który może być napisany w dowolnym popularnym języku skryptowym, w tym Bash, Python i R. Nextflow jest wspierany przez dużą społeczność programistów i bioinformatyków. Istnieje również [nf-core](https://nf-co.re/pipelines/), duża biblioteka potoków bioinformatycznych open-source napisanych w Nextflow.\n",
    "* Wykorzystuje język Groovy.\n",
    "* Silna integracja ze środowiskami kontenerowymi (Docker, Singularity).\n",
    "* Wysoka elastyczność w obsłudze plików, wykonywaniu zadań i zrównoleglaniu.\n",
    "* Kompatybilność ze środowiskami chmurowymi i klastrowymi (AWS, Google Cloud, Slurm itp.).\n",
    "\n",
    "Najpopularniejszy pipeline do analizy danych germinalnych i somatycznych z sekwencjonowania NGS to [nf-core/sarek](https://nf-co.re/sarek/3.4.4/). Potok ten jest podzielony na kilka składowych częsci:\n",
    "* [workflows/sarek/main.nf](https://github.com/nf-core/sarek/blob/3.4.4/workflows/sarek/main.nf) - Główny plik \"workflow\" określający poszczególne kroki takie jak przygotowanie danych, uliniowienie czy wykrywanie wariantów z użyciem zaimportowanych subworkflow's oraz modułów. Poniżej przykład importu informacji ze skryptu do uliniowienia plików fastq:\n",
    "* [subworkflows/local/fastq_align_bwamem_mem2_dragmap_sentieon/main.nf](https://github.com/nf-core/sarek/blob/3.4.4/subworkflows/local/fastq_align_bwamem_mem2_dragmap_sentieon/main.nf) - Pośrednie pliki \"subworkflow\" definiujące kroki w poszczególnych pomniejszych etapach, np. jak uliniowienie w pliku \n",
    "* [modules/bwa/mem/main.nf](https://github.com/nf-core/sarek/blob/3.4.4/modules/nf-core/bwa/mem/main.nf) - pliki \"modules\" definiujące pliki wejściowe i wyjściowe dla poszczególnych programów oraz ich uruchomienie\n",
    "\n",
    "### Common Workflow Language\n",
    "<div>\n",
    "<img src=\"https://repository-images.githubusercontent.com/24454775/a0f7b480-04d7-11eb-9513-240001f2f87a\"\n",
    "width=400/>\n",
    "</div>\n",
    "\n",
    "[Strona WWW](https://www.commonwl.org/user_guide/) \\\n",
    "[Narzedzia do uruchamiania skrytpów CWL](https://www.commonwl.org/implementations/) \\\n",
    "Common Workflow Language (lub CWL) to język służący do definiowania przepływów pracy w sposób wieloplatformowy. CWL zapewnia prosty i dobrze zdefiniowany format do automatyzacji tych analiz poprzez określenie ich etapów i połączeń za pomocą plików CWL. Ekosystem CWL powiększył się o narzędzia do wizualizacji przepływu pracy, graficzne edytory przepływu pracy, biblioteki do programowej interakcji z CWL oraz narzędzia konwertujące do i z CWL oraz innych formatów przepływu pracy.\n",
    "* Wykorzystuje YAML/JSON do definiowania przepływów pracy, kładąc nacisk na prostotę i czytelność.\n",
    "* Oddziela definicje narzędzi i przepływy pracy, aby umożliwić ponowne wykorzystanie komponentów.\n",
    "* Silna społeczność i skupienie na standardach, często postrzegane jako „klej” do łączenia narzędzi bioinformatycznych w różnych systemach.\n",
    "* Zaprojektowany z myślą o szerokiej kompatybilności, umożliwiając uruchomienie tego samego przepływu pracy na różnych platformach przy minimalnych zmianach.\n",
    "\n",
    "\n",
    "### Workflow Description Language\n",
    "<div>\n",
    "<img src=\"https://vsmalladi.github.io/openwdl.github.io//media/logo-preview.png\"\n",
    "width=400/>\n",
    "</div>\n",
    "\n",
    "[Strona WWW](https://docs.openwdl.org/getting-started/quickstart.html) \\\n",
    "[Narzedzia do uruchamiania skrytpów WDL](https://github.com/openwdl/wdl/tree/legacy?tab=readme-ov-file#software-and-tools) \\\n",
    "[Repozytoria potoków w WDL](https://github.com/openwdl/wdl/tree/legacy?tab=readme-ov-file#published-workflows) \\\n",
    "Workflow Description Language (WDL) to deklaratywny język przeznaczony do definiowania przepływów pracy związanych z przetwarzaniem danych w prosty i czytelny sposób. Jest on używany głównie w bioinformatyce, ale jest wystarczająco elastyczny dla różnych zastosować.\n",
    "* Prosta składnia, ułatwiająca czytanie i pisanie skryptów.\n",
    "* Silne wsparcie dla genomiki, zintegrowane z Cromwell (silnik wykonawczy).\n",
    "* Możliwość rozszerzenia na różne środowiska chmurowe i HPC.\n",
    "\n",
    "\n",
    "***\n",
    "# Tworzenie potoków przetwarzania danych z użyciem języka WDL i programu Cromwell\n",
    "\n",
    "### Pobranie programu Cromwell do wykonywania skryptów WDL\n",
    "Program jest dostępny do pobrania ze strony [github projektu](https://github.com/broadinstitute/cromwell). \\\n",
    "[Wstęp do Cromwell](https://cromwell.readthedocs.io/en/latest/tutorials/FiveMinuteIntro/) - Obszerna dokumentacja zawiera m.in. informację o instalacji oraz stworzeniu pierwszego potoku.\n",
    "\n",
    "Na początku należy pobrać plik jar niezbędny do uruchomienia programu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://github.com/broadinstitute/cromwell/releases/download/87/cromwell-87.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu przetestowania działania programu należy uruchomić przykładowy skrypt WDL. Cromwell korzysta z Javy w wersji 11, dlatego przed każdą komendą uruchamiania programu specyfikujemy ścieżkę gdzie w systemie (w naszym przypadku system w obrazie Dockera) znajduje się odpowiednia wersja Javy. Skrypt znajduje się katalogu `dags/cromwell-test.wdl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
    "run dags/cromwell-test.wdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WDL jest językiem deklaratywnym, co oznacza, że koncentruje się na tym, co należy zrobić, a nie na tym, jak to wykonać. Użytkownik opisuje dane wejściowe, polecenia i dane wyjściowe każdego kroku, a silnik (w naszym przypadku Cromwell) obsługuje planowanie zadań, zarządzanie zależnościami i przechowywanie plików.\n",
    "\n",
    "Na dzisiejszych zajęciach będziemy używać Cromwell w trybie `run` który jest polecany do budowania oraz testowania potoków ze względu na prostotę obługi oraz łatwość.\n",
    "\n",
    "Tryb `run` jest najlepszy do szybkiego wykonywania pojedynczych potoków na komputerze lokalnym. Jest prosty w użyciu, nie wymaga konfiguracji serwera, dzięki czemu doskonale nadaje się do testowania i debugowania. Jest on jednak ograniczony ze względu na możliwość uruchomienia tylko jednego potoku na raz oraz brak możliwości wznowienia analizy po nagłym przerwaniu.\n",
    "\n",
    "Tryb `server` działa jako usługa z interfejsem API HTTP, umożliwiając jednoczesne zarządzanie i monitorowanie wielu przepływów pracy. Tryb ten nadaje się do rozwiązań produkcyjnych lub dla wielu użytkowników, umożliwiając automatyczne przesyłanie, monitorowanie w czasie rzeczywistym i kolejkowanie przepływów pracy. Wymaga dodatkowej konfiguracji, takiej jak zapasowa baza danych, w celu zapewnienia odporności na nagłe przerwania oraz skalowalności.\n",
    "\n",
    "\n",
    "***\n",
    "### Struktura skrytpów WDL\n",
    "\n",
    "W folderze `dags` w pliku `alignment.wdl` zapisany jest krótki potok przetwarzania danych mający na celu uliniowienie plików FASTQ oraz konwersję wynikowego pliku do formatu BAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat dags/alignment.wdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schemat przepływu pracy WDL składa się z opisów przepływów pracy (Workflows) i zadań (Tasks):\n",
    "\n",
    "* **Workflow:** Definiuje wysokopoziomową sekwencję kroków i przepływ danych. Przepływ pracy łączy wiele zadań i ustanawia logiczne zależności między nimi.\n",
    "* **Task:** Definiuje poszczególne kroki w ramach przepływu pracy. Każde zadanie określa instrukcje wiersza poleceń, dane wejściowe i wyjściowe dla określonego kroku obliczeniowego.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Zadanie 7_1:</b> Przyglądając się plikowi <b>dags/alignment.wdl</b> podaj nazwy obydwu kroków oraz jakie przyjmują pliki wejściowe\n",
    "</div>\n",
    "\n",
    "W pliku `alignment-inputs.json` podane są ścieżki do plików które określone są jako pliki wejściowe na początku pliku wdl `alignment.wdl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat dags/alignment-inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przepływie pracy WDL zadania wykonywane są zgodnie z ich zależnościami:\n",
    "\n",
    "* Zadania mogą działać równolegle, jeśli nie zależą od siebie nawzajem.\n",
    "* Jeśli zadanie wymaga danych wyjściowych z innego zadania jako danych wejściowych, będzie czekać na zakończenie tego zależnego zadania.\n",
    "\n",
    "Ten łańcuch zależności pozwala WDL automatycznie zarządzać transferami plików, planowaniem i monitorowaniem zadań.\n",
    "\n",
    "***\n",
    "### Uruchamianie potoku do uliniowienia plików FASTQ i konwersji wynikowego pliku SAM do formatu BAM\n",
    "Uruchomienie potoku wymaga w tym przypadku podania również lokalizacji pliku ze ścieżkami do plików wejściowych za pomocą opcji `-i`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
    "run dags/alignment.wdl -i dags/alignment-inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyjrzyjmy się plikom w folderach wynikowych `cromwell-executions`. Każdy z uruchamianych skryptów WDL tworzy folder o nazwie takie samej jak w nagłówku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyciągnięcie informacji o nazwie potoku\n",
    "! sed -n '3,3p' dags/alignment.wdl\n",
    "# Listowanie zawartości folderu\n",
    "! ls cromwell-executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejny folder ma nazwę nadawaną losowo, natomiast w  nim znajdziemy foldery z nazwami związanymi z poszczególnymi etapami określonymi w skrypcie WDL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyciągnięcie informacji o nazwach zadań\n",
    "! sed -n '17,18p;29,30p' dags/alignment.wdl\n",
    "# Listowanie zawartości folderu\n",
    "! ls -d cromwell-executions/alignment_pipeline/*/call-*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Zadanie 7_2:</b> Przyjrzyj się plikom w folderach <b>inputs</b> oraz <b>execution</b>. Jakie rodzaje plików w nich znajdziemy?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku pierwszego kroku `BwaMem` pliki wejściowe pobierane są zgodnie z plikiem `alignment-inputs.json`, natomiast plik wejściowy dla kolejnego etapu `SamToBam` stanowi plik wynikowy z kroku wcześniejszego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed -n '29,32p;59,62p' dags/alignment.wdl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dzięki przekazywaniu plików wynikowych z jednego etapu jako plików wejściowych następnego etapu tworzymy podstawowy potok w którym dane przepływają oraz analizowane są w zdefiniowany sposób.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://docs.openwdl.org/assets/header.F2GrGx5o.png\"\n",
    "width=400/>\n",
    "</div>\n",
    "\n",
    "[Przykłady łączenia etapów w sekwencji](https://docs.openwdl.org/design-patterns/linear-chaining/)\n",
    "\n",
    "Jednak nasz potok danych jest niepełny, brakuje w nim kilku etapów chociażby wykrywania wariantów.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Zadanie 7_3:</b> Dodaj krok wykrywania wariantów z użyciem narzędzia GATK HaplotypeCaller, który nazwij <b>GatkHc</b> gdzie plikami wejściowymi będą plik BAM z etapu SamToBam oraz plik FASTA genomu referencyjnego. Zapisz nowy potok pod nazwą <b>dags/alignment-vc.wdl</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
    "run dags/alignment-vc.wdl -i dags/alignment-inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodawanie kolejnych kroków wymaga dobrego rozeznania w poszczególnych etapach całego potoku oraz ścisłego ustalenia poszczególnych plików wejściowych i ustawień programu. Jednak obsługa dynamicznych konstrukcję ścieżek i osadzanie parametrów za pomocą wyrażeń takich jak  `~{}` ułatwia obsługę zmiennych nazw plików, katalogów pośrednich i sparametryzowanych poleceń.\n",
    "\n",
    "***\n",
    "### Analiza wielu plików jednocześnie\n",
    "\n",
    "Jednak rozszerzanie potoku o dodatkowe kroki to połowa sukcesu. Niezwykle ważna w kontekście wydajności potoku jest możliwość jednoczesnej analizy wielu plików wejściowych jednocześnie. Do tego celu używany jest `scatter` czyli funkcjonalność WDL służąca do zrównoleglania potoku (lub niektórych jego części) przez iterację nad każdym elementem w tablicy (`Array`). Tworzy oddzielną instancję zadania dla każdego elementu tablicy, uruchamiając zadania dla każdego elementu niezależnie i jednocześnie, jeśli pozwalają na to zasoby obliczeniowe.\n",
    "\n",
    "Aby wykorzystać `scatter` należy stworzyć tablicę (`Array`), która w WDL stanowi kolekcję elementów tego samego typu. Tablice umożliwiają potokom obsługę wielu danych wejściowych dla podobnego zadania, umożliwiając przekazywanie listy plików, ciągów znaków, liczb całkowitych lub innych typów danych.\n",
    "\n",
    "[Przykłady wykorzystania funkcjonalności scatter](https://docs.openwdl.org/design-patterns/scatter-gather/#scatter-gather)\n",
    "\n",
    "W celu lepszego zrozumienia rodzaju danych wejściowych zerknijmy na plik ze ścieżkami `dags/alignment-inputs-trio.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sed -n '8,19p' dags/alignment-inputs-trio.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ścieżki do plików FASTQ poszczególnych członków rodziny zostały zagnieżdżone w zmiennej `fastq_files`, podobna lista została również utworzona dla zmiennej `sample_names` i zawiera nazwy poszczególnych członków rodziny. Stwarza to możliwość iterowania po tych listach, czyli wybierania elementów listy według ich indeksów i wykonywanie na nich kolejnych etapów analizy.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Zadanie 7_4:</b> Zmodyfikuj skrypt <b>dags/alignment-vc.wdl</b> w taki sposób, aby umożliwiał równoległe procesowanie wszystkich próbek w rodzinie (mother, father, son) na poszczególnych etapach potoku. Użyj opcji <b>Array</b> dla plików wejściowych oraz polecenia <b>scatter()</b> dla zrównoleglenia wykonywanych czynności. Zapisz skrypt pod nazwą <b>dags/alignment-vc-trio.wdl</b>. Użyj zmodyfikowanego pliku ze ścieżkami do plików wejściowych <b>dags/alignment-inputs-trio.json</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
    "run dags/alignment-vc-trio.wdl -i dags/alignment-inputs-trio.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rozgałęzianie oraz scalanie etapów potoku\n",
    "<div>\n",
    "<img src=\"https://docs.openwdl.org/assets/header.DpTZgXLq.png\"\n",
    "width=400/>\n",
    "</div>\n",
    "\n",
    "Do tej pory wykorzystywaliśmy prosty schemat wykonywania operacji jedna po drugiej. Natomiast często niektóre elementy potoku będą wykonywane na innych zbiorach plików lub będą korzystały z plików wynikowych z różnych etapów. Przykładem może być analiza jakościowa wykonywana za pomocą `MultiQC` które wykorzystuje wyniki z różnych narzędzi uruchamianych na poszczególnych etapach potoku.\n",
    "\n",
    "[Przykłady rozgałęziania i scalania etapów](https://docs.openwdl.org/design-patterns/branch-and-merge/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Zadanie 7_5:</b> Zmodyfikuj skrypt <b>dags/alignment-vc.wdl</b> poprzez dodanie etapów analizy <b>FastQC</b> na plikach FASTQ, <b>samtools flagstat</b> na plikach BAM oraz <b>bcftools stats</b> na plikach VCF. Na końcu dodaj krok analizy danych wynikowych z tych programów z użyciem <b>MultiQC</b>. Zapisz skrypt pod nazwą <b>dags/alignment-vc-trio-qc.wdl</b>.\n",
    "</div>\n",
    "\n",
    "Dla programu FastQC ustal wersję Javy którą ma używać za pomoca opcji: \\\n",
    "`-j /usr/lib/jvm/java-11-openjdk-amd64/bin/java`.\n",
    "\n",
    "Wcześniej zainstalowaliśmy brakujące MultiQC przed którego wywołaniem trzeba użyć komendy: \\\n",
    "`export XDG_CONFIG_HOME=work/git/edugen-notebooks/20Z/dags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /usr/lib/jvm/java-11-openjdk-amd64/bin/java -jar cromwell-87.jar \\\n",
    "run dags/alignment-vc-trio-qc.wdl -i dags/alignment-inputs-trio.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edugen",
   "language": "python",
   "name": "edugen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
