{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big data w genomice \n",
    "\n",
    "Zakres zajęć:\n",
    "* wprowadzenie do środowiska chmury obliczeniowej, omówienie architektury rozwiązań zbudowanych w oparciu o Apache Spark i Kubernetes\n",
    "* obiektowa pamięć masowa\n",
    "* zrównoleglony potok przetwarzania\n",
    "* dostęp/analiza/wizualizacja danych poprzez rozproszone operacje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Środowisko Google Kubernetes Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](gke.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obiektowa pamięć masowa (Google Cloud Storage)\n",
    "\n",
    "**Projekt**\n",
    "* Wszystkie dane przynależą do konkretnego projektu.\n",
    "* Do projektu mogą mieć dostęp użytkownicy.\n",
    "* Projekt ma zdefiniowane metody uwierzytelniające, rozliczenia, monitorowanie etc.\n",
    "\n",
    "**Kubełek (bucket)** to kontener na pliki/obiekty.\n",
    "* Nazwa Bucketu musi być unikalna w skali całej usługi u wszystkich użytkowników (!)\n",
    "* Kubełków nie można zagnieżdzać\n",
    "* W kubełkach możemy tworzyć foldery i tam logicznie grupować pliki.\n",
    "* Kubełek wraz z zawartością może zostać udostępniony publicznie.\n",
    "* Kubełkowi nie można zmienić nazwy lub metadanych. Trzeba go usunąć i stworzyć ponownie. \n",
    "\n",
    "**Obiekt**\n",
    "* obiekty przechowywane w kubełkach\n",
    "* obiekty mają zawartość oraz metadane\n",
    "* obiekty są niemodyfikowalne\n",
    "\n",
    "Do operacji na Google Storage można wykorzystać narzędzie `gsutil`:\n",
    "\n",
    "Operacje na kubełkach\n",
    "* listowanie kubełków (buckets) - `ls`\n",
    "* tworzenie nowego kubełka - `mb`\n",
    "* usuwania kubełka - `rm`\n",
    "* listowanie zawartości kubełków - `ls`\n",
    "* udostępnianie - `iam`\n",
    "\n",
    "Operacje na obiektach\n",
    "* dodawania pliku do kubełka - `cp`\n",
    "* kopiowanie między kubełkami - `cp`\n",
    "* usuniecie z kubełka - `cp`\n",
    "* pobranie informacji o obiekcie - `stat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil mb gs://edugen-lab-$USER  # stworzenie bucketu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -L -b gs://edugen-lab-$USER # listowanie zawartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil du -s  gs://edugen-lab-$USER # ile zajmuje przestrzeni?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -r gs://edugen-lab-$USER/ # listowanie zawartosci kubełka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp gs://edugen-data/coriell_chr1.fq gs://edugen-lab-$USER/data/  # upload obiektu do kubełka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -r gs://edugen-lab-$USER/ # listowanie zawartosci kubełka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark na GKE\n",
    "\n",
    "* Apache Spark platforma ogólnego zastosowania, opensource, do przetwarzania duzych zbiorow danych.\n",
    "* Posiada  API dla języków programowania: Scala, Python i R. \n",
    "* Przetwarzanie w Spark przetwarzanie jest wykonywane w większości  wprost w pamięci operacyjnej.\n",
    "* Przeznaczenie: do uruchamiania  aplikacji i skryptów z wykorzystaniem uczenia maszynowego lub interaktywnych kwerend.\n",
    "* Spark ten wspiera SQL (typ DataFrames), przetwarzanie strumieniowe oraz przetwarzanie grafów.\n",
    "* Integracja z lokalną pamięci masową, rozproszonymi lub obiektowymi systemu plików.\n",
    "* Spark można uruchamić na pojedynczej maszynie na środowisku klastrowym, lub w chmurze. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".config('spark.driver.memory','1g') \\\n",
    ".config('spark.executor.memory', '2g') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odczyty nieuliniowione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_path = \"gs://edugen-data/coriell_chr1.fq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edugen",
   "language": "python",
   "name": "edugen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
