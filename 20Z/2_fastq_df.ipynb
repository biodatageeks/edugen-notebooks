{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie sesji Spark\n",
    "Zainicjowanie sesji Spark oraz stworzenie schematu bazy danych z której będziemy korzystać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".config('spark.driver.memory','1g') \\\n",
    ".config('spark.executor.memory', '2g') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobranie sesji Spark jest proste dla programisty korzystającego z notatnika, wymaga podania tylko kilku parametrów, ale faktyczna konfiguracja jest bardziej rozbudowana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "args = os.environ['PYSPARK_SUBMIT_ARGS'].replace(\"  \", \"\\n\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy pobraną sesję sparkową. Powstały dodatkowe pody gotowe na realizację obliczeń. A jak zwolnić te zasoby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponownie pobieramy sesję Spark. Będziemy z niej korzystać. Po zakończonej pracy należy pamiętać o zastopowaniu sesji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".config('spark.driver.memory','1g') \\\n",
    ".config('spark.executor.memory', '2g') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odczyt danych\n",
    "Korzystając z sesji Spark można odczytać dane zapisane w lokalizacji dostępnej dla executorów (procesów obliczeniowych) koordynowanych przez Spark. \n",
    "Konieczne jest podanie ścieżki dostępowej do pliku i formatu danych (nie jest to jednoznazne z rozszerzeniem pliku).\n",
    "Dystrybucja Spark udostępnia kilka tzw Data Sources, które odczytują i zapisują dane w określonych formatach (CSV, formaty kolumnowe: parquet/orc).\n",
    "Data Sources zgodne z opracowanym interfejsem można samodzielnie tworzyć. Na dzisiejszych zajęciach będziemy korzystać z takich zdefiniowanych DS:\n",
    "* FASTQDataSource\n",
    "* BAMDataSource\n",
    "* VCFDataSource\n",
    "\n",
    "**UWAGA - powyższe sposoby odczytu plików nie są częścią głównej dystrybucji Spark. Wymagana jest dodatkowa konfiguracja.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                               # moduł OS języka Python\n",
    "user_name = os.environ.get('USER')      # pobieramy zmienną środowiskową USER\n",
    "bucket = f\"gs://edugen-lab-{user_name}\" # konstruujemy sciezke dostepowa do pliku\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "`Co oznacza f przed cudzysłowem?`\n",
    "\n",
    "`Czy jest różnica między stosowaniem apostrofu i cudzysłowu przy definicji zmiennych przechowywujących łańcuchy znaków?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_path = f\"{bucket}/fastq/*\"  # * oznacza wszystkie pliki we wskazanej lokalizacji. Można podać konkretny plik\n",
    "fastq_all = spark.read.load(reads_path, format=\"org.biodatageeks.sequila.datasources.FASTQ.FASTQDataSource\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weryfikacja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fastq_all)      # jaki jest typ danych utworzonej zmiennej? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.printSchema() # jaki jest schemat danych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fastq_all.columns)           # wymiary (liczba kolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.count()               # wymiary (liczba wierszy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.explain(True)              #  plan wykonania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame jest abstrakcją nad innym typem danych (RDD), który jest podstawową rozproszoną strukturą danych. Poprzez DF możemy dostać się do rdd i zweryfikować na przykład liczbę partycji danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.rdd.getNumPartitions() # liczba partycji (bloków danych)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podgląd danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.show(5)  # pierwsze 5 wierszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.show(truncate=False) # bez skracania zawartości kolumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widok \"szerokich\" tabel jest nieczytelny, w kolejnych częściach warsztatów zaradzimy temu korzystając z dodatkowej biblioteki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dostęp do wybranych danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operacja projekcji (SELECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.select(\"sample_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Czy operacja select (sample_id) wpłynęła na oryginalny data frame fastq_all?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.printSchema()\n",
    "fastq_all.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli chcemy zachować wynik działania transformacji (w celu późniejszego wykorzystania) trzeba wynik zachować w zmiennej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_sample_only = fastq_all.select(\"sample_id\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_sample_only.printSchema()\n",
    "fastq_sample_only.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.select(\"sample_id\",\"seq\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powiedzmy, że interesują nas wszystkie kolumny poza qual. Jak to zrobic? Można wylistować wszystkie kolumny poza qual, ale to uciazliwe. Mozna skorzystac z operacji drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_no_qual=fastq_all.drop('qual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Czy operacja usunięcia kolumny qual wpłynęła na oryginalny data frame fastq_all?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_no_qual.printSchema()\n",
    "fastq_no_qual.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE  </span>\n",
    "\n",
    "Stwórz nową ramkę danych która będzie zawierać wszystkie kolumny z fastq_all poza pos_x i pos_y. Wyświetl 10 wierszy z tej kolekcji pokazując pełną zawartość kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_cropped = fastq_all.drop('pos_x', 'pos_y')\n",
    "fastq_cropped.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wartości unikalne\n",
    "Jeśli chcemy uzyskać unikalne wartości w określonych kolumnach korzystamy z metody distinct().\n",
    "Operacje na DF można łańcuchowo łączyć, zatem na wyniku działania select() można wywołać kolejne metody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.select('sample_id').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.select('sample_id', 'filter_passed').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sortowanie\n",
    "\n",
    "Do sortowania służy metoda orderBy. Domyślne sortowanie jest rosnące."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.select('sample_id').distinct().orderBy('sample_id').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.select('sample_id').distinct().orderBy('sample_id', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.orderBy('sample_id', 'seq', ascending=False).show()  # kierunek sortowania jest wspólny dla listy kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.orderBy('sample_id', ascending=False).orderBy('seq', ascending=True).show() # sortowanie malejace i rosnące na dwóch roznych kolumnach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrowanie wynikow\n",
    "Nasz zbiór danych posiada odczyty z 3 próbek. Ograniczmy się do wybranych próbek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_mother = fastq_all.filter(\"sample_id = 'mother'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Czy już odbył się odczyt danych z fastq?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_mother.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_mother.select('sample_id').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_mother.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warunki można łączyć spójnikami logicznymi. \n",
    "Można używać\n",
    "* operatorów arytmetycznych (=, !=, >, >=, <, <=)\n",
    "* przynależności do zbioru (IN/NOT IN) \n",
    "* porównania znaków (LIKE/NOT LIKE)\n",
    "* przyrównania do wartości NULL (IS NULL/ IS NOT NULL)\n",
    "\n",
    "Przy korzystaniu z LIKE można użyć % jako oznaczenie dowolnego ciągu znaków.\n",
    "\n",
    "Konstrukcja warunku w metodzie filter() jak taka jak w klauzuli WHERE W SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokaż odczyty spełniające warunek ze nazwa instrumentu jest pusta, run_id jest >=0 a odczyt zaczyna sie od liter GCA. Pokaz tylko kolumny z filtra oraz nazwe probki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_mother.filter('instrument_name IS NULL and run_id>=0 and seq LIKE \"GCA%\"').select('sample_id', 'instrument_name', 'run_id', 'seq').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_mother.select('sample_id', 'instrument_name', 'run_id', 'seq').filter('instrument_name IS NULL and run_id>=0 and seq LIKE \"GCA%\"').show() # kolejnosc select i filter bez znaczenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE  </span>\n",
    "\n",
    "Napisz polecenie które policzy ile jest rekordów dla próbki syna które spełniają warunki, że sekwencja odczytu konczy się na TGG a qual zaczyna się od ==."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.filter(\"sample_id='son' and seq LIKE '%TGG' and qual LIKE '==%' \").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uzywanie funkcji, kolumny wyliczane\n",
    "\n",
    "Dostępne są funkcje skalarne (przykład: ROUND, UPPER, CURRENT_DATE) oraz agregujące (MIN, MAX, AVG, SUM, COUNT).\n",
    "Niektóre funkcje są dostępne \"od razu\" bez dodatkowych poleceń import. \n",
    "Lista funkcji znajduje się : https://spark.apache.org/docs/latest/api/sql/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.selectExpr(\"*\").show()  # pokaż wszystkie kolumny tego DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodanie dwóch dodatkowych kolumn wyliczanych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.selectExpr(\"*\", \"length(seq) as len_seq\", \"length(qual) as len_qual\" ).show() ## dodanie dwóch kolumn wyliczanych przy uzyciu funkcji LENGTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alias - nadanie kolumnie lub kolumnie wyliczanej nazwy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_fastq = fastq_all.selectExpr(\"*\", \"length(seq) as len_s\", \"length(qual) as len_q\" ).drop('instrument_name', 'flowcell_id', 'filter_passed','control_num') # AS alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_fastq.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodanie nowej kolumny, dla każdego wiersza zostanie dodana wartość zwracana przez funkcję current_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date\n",
    "extended_fastq.withColumn (\"date\", current_date()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodanie kolumny o stałej wartości dla każdej wartości wymaga wykorzystania funkcji lit (), która przekształci stała wartość w kolumnę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "extended_fastq.withColumn(\"imported_by\", lit(user_name)).withColumn(\"format\", lit('FASTQ')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE  </span>\n",
    "\n",
    "Napisz polecenie które stworzy ramkę danych zawierającą sklejenie wartości dwóch kolumn (sample_id) oraz daty eksperymentu (dodaj kolumne z wartościami 2019-01-15) . W wynikach chcemy mieć tylko dane matki i ojca. Kolumny wynikowe: nazwa próbki, seq, qual, data eksperymentu oraz scalona nazwa probki oraz data eksperymenty (np father-2019-01-15). Posortuj po nazwie próbki. Pokaż schemat ramki. Upewnij się, że data eksperymentu jest typu date. \n",
    "\n",
    "* Zwróć uwagę na potrzebę konwersji ciągu znaków na datę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, lit, concat\n",
    "\n",
    "df = fastq_all.withColumn(\"experiment_date\", to_date(lit('2019-01-15')))\\\n",
    "        .withColumn(\"sample_date\", concat(\"sample_id\", concat(lit(\"-\"), \"experiment_date\")))\\\n",
    "        .select (\"sample_id\", \"sample_date\", \"seq\", \"qual\", \"experiment_date\")\\\n",
    "        .filter (\"sample_id IN ('mother', 'father')\") \\\n",
    "        .orderBy(\"sample_id\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrukcje warunkowe przy kolumnach wyliczanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fastq_dates=fastq_all.selectExpr('*', 'if(sample_id = \"son\",to_date(\"2018-11-10\"), to_date(\"2019-01-15\")) as experiment_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE  </span>\n",
    "\n",
    "Napisz polecenia, które zweryfikuje czy daty eksperymentów zostały dodane poprawnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_dates.printSchema()\n",
    "fastq_dates.show()\n",
    "fastq_dates.select(\"sample_id\", \"experiment_date\").show()\n",
    "fastq_dates.select(\"sample_id\", \"experiment_date\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_all.groupBy(\"sample_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fastq_all.groupBy(\"sample_id\")) # to nie jest DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count=fastq_all.groupBy(\"sample_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count.orderBy(\"count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE  </span>\n",
    "\n",
    "Napisz funkcje, ktora znajdzie rozklady jakosci dla 1, 2, 3 i 4 pozycji odczytu.\n",
    "*Nastepnie zaprezentuj wyniki w postaci serii histogramów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quals = fastq_all.selectExpr( \"ascii(SUBSTR(qual,1)) -33 as p1\", \n",
    "                                    \"ascii(SUBSTR(qual,2))-33 as p2\",\n",
    "                                    \"ascii(SUBSTR(qual,3))-33 as p3\",\n",
    "                                    \"ascii(SUBSTR(qual,4))-33 as p4\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "quals.toPandas().boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapowanie do genomu referencyjnego\n",
    "Wykonamy mapowanie do genomu referencyjnych korzystając z rozproszenia danych miedzy procesy obliczeniowe sparka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowanie ścieżek do plików."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "user_name = os.environ.get('USER')\n",
    "bucket = f\"gs://edugen-lab-{user_name}\"\n",
    "\n",
    "reads_file_path = f\"{bucket}/fastq/mother.fastq\"\n",
    "ref_path = \"/mnt/data/mapping/ref/ref.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konstruujemy komendę, która będzie uruchamiana na procesach obliczeniowych. Potrzebne narzędzia muszą być dostępne na węzłach obliczeniowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'bwa mem -p {ref_path} - | samtools fixmate -m - - | samtools sort  | samtools markdup -r -S - -  | samtools addreplacerg  -r \"ID:S1\" -r \"SM:S1\"  -r \"PL:ILLUMINA\" - | samtools view -b -'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby wykonać rozproszone obliczenia na danych genomicznych nalezy wykorzystac dodatkową bibliotekę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyseqtender import SeqTenderAlignment\n",
    "\n",
    "seq_aligner = SeqTenderAlignment(spark, reads_file_path, command)\n",
    "alignments_rdd = seq_aligner.pipe_reads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapisujemy plik na kubełek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bam_file_path = f\"{bucket}/bam/mother10.bam\"\n",
    "seq_aligner.save_reads(bam_file_path, alignments_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls gs://edugen-lab-$USER/bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='background:yellow'> ZADANIE  </span>\n",
    "\n",
    "Na podstawie notatników z zajęć z genomiki wyświetl fragment pliku BAM w widge'cie IGV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# najpierw trzeba upublicznić kubełek\n",
    "!gsutil iam ch allUsers:objectViewer $bucket\n",
    "\n",
    "from igv_jupyterlab import IGV\n",
    "igv = IGV(genome=\"hg19\" )\n",
    "display(igv)\n",
    "import time\n",
    "time.sleep(3)\n",
    "t1 = igv.create_track(\n",
    "        name = \"mother BAM\",\n",
    "        url = f\"{bucket}/bam/mother10.bam\",\n",
    "        index_url= f\"{bucket}/bam/mother10.bam.bai\",\n",
    "        indexed= True\n",
    ")\n",
    "\n",
    "igv.load_track(t1)\n",
    "\n",
    "igv.search_locus(\"20\", 10002294, 10002623)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kończymy notatniki, należy zamknąć sesję."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edugen",
   "language": "python",
   "name": "edugen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
